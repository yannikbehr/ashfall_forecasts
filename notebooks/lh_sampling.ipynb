{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "from lh_sampling.sampler import lhs, resample\n",
    "from lh_sampling.visualise import lhs_example_plot, plot_lhs, scatter_matrix_plot\n",
    "from lh_sampling.util import read_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing representative samples\n",
    "To quantify uncertainty of ashfall forecasts in the absence of observational contstraints on eruption parameters we have to define good prior distributions and then draw representative samples from these distributions. Since we are limited in the number of samples we can draw by the number of weather forecast ensemble members, we are using Latin hypercube sampling (LHS). LHS is a type of stratefied sampling that ensures that every section of the parameter space is sampled once. The figure below shows an example of a random uniform sample (green dots) and the corresponding LHS sample (black crosses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lhs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure demonstrates that the variance in the LHS estimates of the first and second moment reduce faster than for standard Monte-Carlo estimates. a) shows the 2D Gaussian distribution from which samples are drawn; b) and c) show the LHS and Monte Carlo estimate, respectively, from 20 random samples. d) to f) show the evolution of the estimates of first and second moment for LHS and Monte Carlo samples with respect to the number of samples. We can see that LHS requires less samples to generate a representative eruption parameter ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = lhs_example_plot(seed=42)\n",
    "fout = 'plots/lhs_example.png'\n",
    "fig.write_image(fout, scale=2)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eruption database\n",
    "To construct the prior distribution we first assembled a database of eruption parameters (column height, mass eruption rate (MER), duration) from 213 historic eruptions. We then construct probability density functions (PDFs) for these parameters, either by approximating the cumuluative distribution function (CDF) with a mathmatical function or by fitting a gaussian distribution to the eruption parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following figure shows the distribution of eruption parameters in the database coloured by magma type. The diagonal panels shows CDFs, the upper panels show the data points, and the lower panels kernel density estimates of the same data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_db()\n",
    "fig = scatter_matrix_plot(df, hue='Magma type')\n",
    "fout = 'plots/db_overview.png'\n",
    "fig.savefig(fout, dpi=300)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure below shows in blue the original data points for eruptions with predominantely mafic magma. Shown in orange are the resampled datapoints which were generated by approximating the first and second moment of the original distribution and then drawing 20 LHS samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df[['log Column height [km]', 'log MER [kg/s]', 'log Duration [h]']].where(df['Magma type'] == 'Mafic')\n",
    "dfr = resample(df_m, constraints=[np.log(25), np.log(2e7), np.log(24)], seed=42)\n",
    "fig = scatter_matrix_plot(dfr, hue='Category', log=True)\n",
    "fout = 'plots/lhs_mafic.png'\n",
    "fig.savefig(fout, dpi=300)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df[['log Column height [km]', 'log MER [kg/s]', 'log Duration [h]']].where(df['Magma type'] == 'Intermediate')\n",
    "df_ir = resample(df_i, nsamples=30, constraints=[np.log(25), np.log(2e9), np.log(24)], seed=42)\n",
    "df_ir = df_ir[df_ir.Category == 'resampled']\n",
    "df_ir['MER [kg/s]'] = np.exp(df_ir['log MER [kg/s]'])\n",
    "df_ir['Column height [km]'] = np.exp(df_ir['log Column height [km]'])\n",
    "df_ir['Duration [h]'] = np.exp(df_ir['log Duration [h]'])\n",
    "df_ir.drop(columns=['log MER [kg/s]', 'log Duration [h]', 'log Column height [km]', 'Category'], inplace=True)\n",
    "df_ir.reset_index(drop=True, inplace=True)\n",
    "df_ir.to_csv('data/lh_sample_intermediate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "g = sns.PairGrid(df_ir, diag_sharey=False)\n",
    "g.map_upper(sns.scatterplot, s=15)\n",
    "g.map_lower(sns.kdeplot)\n",
    "g.map_diag(sns.histplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is a purely statistical approach, the alternative would be to find functional forms of PDFs. The following shows an example to describe MER for eruptions at Etna volcano. The advantage of a functional form may be that it can be transferred and scaled to other volcanoes by considering different physical constraints. The disadvantage is that it is more difficult to derive functional forms for all three eruption parameters which also take into account the covariance structure. The figure also shows the result of approximating the MER data with a Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from lh_sampling.util import ecdf\n",
    "\n",
    "df_etna = df[df['Volcano']=='Etna']\n",
    "df_etna = df_etna.sort_values(axis=0, by='MER')\n",
    "dfr = resample(df_etna[['log Column height [km]', 'log MER [kg/s]', 'log Duration [h]']].copy())\n",
    "\n",
    "x = df_etna['MER'].values\n",
    "x_sorted, cdf = ecdf(x)\n",
    "xr = dfr['log MER [kg/s]'].values\n",
    "x_sortedr, cdfr = ecdf(xr)\n",
    "\n",
    "def fitfun(data, a, b):\n",
    "    return -a*np.log10(data)+b\n",
    "prms, _ = curve_fit(fitfun, x_sorted, 1-cdf, p0=[19, 100])\n",
    "\n",
    "with plt.style.context('seaborn'):\n",
    "    plt.loglog(x, fitfun(x_sorted, prms[0], prms[1]), label='Best fit')\n",
    "    plt.loglog(x_sorted, 1-cdf, label='Complementary CDF')\n",
    "    plt.semilogx(np.exp(x_sortedr), 1-cdfr, label='Complementary CDF (Gaussian)')\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lhs",
   "language": "python",
   "name": "lhs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
